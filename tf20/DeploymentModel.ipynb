{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv('/Users/Bryan/Documents/Programming/Python_Courses/Tensorflow2/DATA/iris.csv')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "1             4.9          3.0           1.4          0.2\n",
       "2             4.7          3.2           1.3          0.2\n",
       "3             4.6          3.1           1.5          0.2\n",
       "4             5.0          3.6           1.4          0.2\n",
       "..            ...          ...           ...          ...\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = iris.drop('species', axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         setosa\n",
       "1         setosa\n",
       "2         setosa\n",
       "3         setosa\n",
       "4         setosa\n",
       "         ...    \n",
       "145    virginica\n",
       "146    virginica\n",
       "147    virginica\n",
       "148    virginica\n",
       "149    virginica\n",
       "Name: species, Length: 150, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = iris['species']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to code outputs as dummies or one hot encoding\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = encoder.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split and scale data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only fit to the training set\n",
    "\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units = 4, activation='relu', input_shape=[4,]))\n",
    "model.add(Dense(units = 3, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 1.2069 - accuracy: 0.1583 - val_loss: 1.2012 - val_accuracy: 0.1000\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2014 - accuracy: 0.1583 - val_loss: 1.1961 - val_accuracy: 0.1000\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1965 - accuracy: 0.1417 - val_loss: 1.1908 - val_accuracy: 0.1000\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1913 - accuracy: 0.1250 - val_loss: 1.1857 - val_accuracy: 0.1333\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1863 - accuracy: 0.1000 - val_loss: 1.1807 - val_accuracy: 0.1333\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1813 - accuracy: 0.0833 - val_loss: 1.1758 - val_accuracy: 0.1000\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1760 - accuracy: 0.0750 - val_loss: 1.1712 - val_accuracy: 0.1000\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1719 - accuracy: 0.0500 - val_loss: 1.1659 - val_accuracy: 0.1000\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1667 - accuracy: 0.0583 - val_loss: 1.1608 - val_accuracy: 0.1333\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1621 - accuracy: 0.0583 - val_loss: 1.1561 - val_accuracy: 0.1333\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1574 - accuracy: 0.0500 - val_loss: 1.1517 - val_accuracy: 0.1000\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1531 - accuracy: 0.0333 - val_loss: 1.1474 - val_accuracy: 0.1000\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1491 - accuracy: 0.0250 - val_loss: 1.1431 - val_accuracy: 0.1000\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1446 - accuracy: 0.0250 - val_loss: 1.1391 - val_accuracy: 0.0667\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1403 - accuracy: 0.0250 - val_loss: 1.1352 - val_accuracy: 0.0667\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1361 - accuracy: 0.0250 - val_loss: 1.1314 - val_accuracy: 0.0667\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1317 - accuracy: 0.0167 - val_loss: 1.1278 - val_accuracy: 0.1000\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1280 - accuracy: 0.0500 - val_loss: 1.1237 - val_accuracy: 0.0667\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1237 - accuracy: 0.0417 - val_loss: 1.1198 - val_accuracy: 0.1000\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1190 - accuracy: 0.0500 - val_loss: 1.1161 - val_accuracy: 0.1000\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1148 - accuracy: 0.0583 - val_loss: 1.1121 - val_accuracy: 0.1000\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1107 - accuracy: 0.0917 - val_loss: 1.1082 - val_accuracy: 0.1333\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1067 - accuracy: 0.1083 - val_loss: 1.1042 - val_accuracy: 0.1333\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1028 - accuracy: 0.1083 - val_loss: 1.1003 - val_accuracy: 0.1667\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0986 - accuracy: 0.1500 - val_loss: 1.0965 - val_accuracy: 0.2333\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0946 - accuracy: 0.1667 - val_loss: 1.0928 - val_accuracy: 0.2333\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0906 - accuracy: 0.1833 - val_loss: 1.0891 - val_accuracy: 0.2333\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0865 - accuracy: 0.2333 - val_loss: 1.0856 - val_accuracy: 0.2333\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0828 - accuracy: 0.2667 - val_loss: 1.0820 - val_accuracy: 0.2333\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0792 - accuracy: 0.2833 - val_loss: 1.0785 - val_accuracy: 0.2333\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0753 - accuracy: 0.2917 - val_loss: 1.0752 - val_accuracy: 0.2667\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0715 - accuracy: 0.3083 - val_loss: 1.0719 - val_accuracy: 0.2667\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0681 - accuracy: 0.3250 - val_loss: 1.0688 - val_accuracy: 0.3000\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0645 - accuracy: 0.3333 - val_loss: 1.0656 - val_accuracy: 0.3000\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0612 - accuracy: 0.3333 - val_loss: 1.0625 - val_accuracy: 0.3333\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0577 - accuracy: 0.3333 - val_loss: 1.0595 - val_accuracy: 0.3333\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0544 - accuracy: 0.3333 - val_loss: 1.0564 - val_accuracy: 0.3333\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0512 - accuracy: 0.3333 - val_loss: 1.0533 - val_accuracy: 0.3333\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0478 - accuracy: 0.3333 - val_loss: 1.0503 - val_accuracy: 0.5667\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0448 - accuracy: 0.6083 - val_loss: 1.0473 - val_accuracy: 0.5667\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0418 - accuracy: 0.6083 - val_loss: 1.0443 - val_accuracy: 0.5667\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0384 - accuracy: 0.6083 - val_loss: 1.0414 - val_accuracy: 0.5667\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0354 - accuracy: 0.6167 - val_loss: 1.0386 - val_accuracy: 0.5667\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0324 - accuracy: 0.6167 - val_loss: 1.0358 - val_accuracy: 0.5667\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0295 - accuracy: 0.6167 - val_loss: 1.0330 - val_accuracy: 0.5667\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0267 - accuracy: 0.6250 - val_loss: 1.0303 - val_accuracy: 0.5667\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0237 - accuracy: 0.6250 - val_loss: 1.0277 - val_accuracy: 0.5667\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0207 - accuracy: 0.6250 - val_loss: 1.0250 - val_accuracy: 0.5667\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0180 - accuracy: 0.6250 - val_loss: 1.0223 - val_accuracy: 0.5667\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0153 - accuracy: 0.6333 - val_loss: 1.0196 - val_accuracy: 0.5667\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0125 - accuracy: 0.6333 - val_loss: 1.0170 - val_accuracy: 0.5667\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0099 - accuracy: 0.6333 - val_loss: 1.0143 - val_accuracy: 0.5667\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0070 - accuracy: 0.6333 - val_loss: 1.0118 - val_accuracy: 0.5667\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0045 - accuracy: 0.6333 - val_loss: 1.0092 - val_accuracy: 0.5667\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0017 - accuracy: 0.6417 - val_loss: 1.0066 - val_accuracy: 0.5667\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9990 - accuracy: 0.6500 - val_loss: 1.0041 - val_accuracy: 0.5667\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9964 - accuracy: 0.6500 - val_loss: 1.0017 - val_accuracy: 0.5667\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9941 - accuracy: 0.6500 - val_loss: 0.9992 - val_accuracy: 0.5667\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9913 - accuracy: 0.6500 - val_loss: 0.9968 - val_accuracy: 0.5667\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9887 - accuracy: 0.6500 - val_loss: 0.9945 - val_accuracy: 0.5667\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9862 - accuracy: 0.6500 - val_loss: 0.9920 - val_accuracy: 0.5667\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9838 - accuracy: 0.6500 - val_loss: 0.9896 - val_accuracy: 0.5667\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9812 - accuracy: 0.6500 - val_loss: 0.9872 - val_accuracy: 0.5667\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9786 - accuracy: 0.6500 - val_loss: 0.9848 - val_accuracy: 0.5667\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9760 - accuracy: 0.6500 - val_loss: 0.9825 - val_accuracy: 0.5667\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9735 - accuracy: 0.6500 - val_loss: 0.9801 - val_accuracy: 0.5667\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9710 - accuracy: 0.6500 - val_loss: 0.9776 - val_accuracy: 0.5667\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9685 - accuracy: 0.6583 - val_loss: 0.9752 - val_accuracy: 0.5667\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9660 - accuracy: 0.6583 - val_loss: 0.9727 - val_accuracy: 0.5667\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9635 - accuracy: 0.6583 - val_loss: 0.9702 - val_accuracy: 0.6000\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9610 - accuracy: 0.6583 - val_loss: 0.9677 - val_accuracy: 0.6000\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9585 - accuracy: 0.6667 - val_loss: 0.9653 - val_accuracy: 0.6000\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9560 - accuracy: 0.6667 - val_loss: 0.9628 - val_accuracy: 0.6000\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9536 - accuracy: 0.6667 - val_loss: 0.9603 - val_accuracy: 0.6000\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9510 - accuracy: 0.6667 - val_loss: 0.9578 - val_accuracy: 0.6000\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9484 - accuracy: 0.6667 - val_loss: 0.9554 - val_accuracy: 0.6000\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9459 - accuracy: 0.6667 - val_loss: 0.9530 - val_accuracy: 0.6000\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9434 - accuracy: 0.6667 - val_loss: 0.9506 - val_accuracy: 0.6000\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9409 - accuracy: 0.6667 - val_loss: 0.9482 - val_accuracy: 0.6000\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9385 - accuracy: 0.6750 - val_loss: 0.9458 - val_accuracy: 0.6000\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9360 - accuracy: 0.6833 - val_loss: 0.9434 - val_accuracy: 0.6000\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9334 - accuracy: 0.6833 - val_loss: 0.9411 - val_accuracy: 0.6000\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9309 - accuracy: 0.6833 - val_loss: 0.9388 - val_accuracy: 0.6000\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9284 - accuracy: 0.6833 - val_loss: 0.9362 - val_accuracy: 0.6000\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9259 - accuracy: 0.6833 - val_loss: 0.9336 - val_accuracy: 0.6000\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9234 - accuracy: 0.6833 - val_loss: 0.9310 - val_accuracy: 0.6000\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9209 - accuracy: 0.6833 - val_loss: 0.9286 - val_accuracy: 0.6000\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9183 - accuracy: 0.6833 - val_loss: 0.9262 - val_accuracy: 0.6000\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9158 - accuracy: 0.6833 - val_loss: 0.9239 - val_accuracy: 0.6000\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9133 - accuracy: 0.6833 - val_loss: 0.9215 - val_accuracy: 0.6000\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9108 - accuracy: 0.6833 - val_loss: 0.9191 - val_accuracy: 0.6000\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9082 - accuracy: 0.6833 - val_loss: 0.9166 - val_accuracy: 0.6000\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9058 - accuracy: 0.6833 - val_loss: 0.9141 - val_accuracy: 0.6000\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9031 - accuracy: 0.6833 - val_loss: 0.9117 - val_accuracy: 0.6000\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9007 - accuracy: 0.6833 - val_loss: 0.9093 - val_accuracy: 0.6000\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8981 - accuracy: 0.6833 - val_loss: 0.9069 - val_accuracy: 0.6000\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8956 - accuracy: 0.6833 - val_loss: 0.9043 - val_accuracy: 0.6000\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8931 - accuracy: 0.6833 - val_loss: 0.9019 - val_accuracy: 0.6000\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8905 - accuracy: 0.6833 - val_loss: 0.8995 - val_accuracy: 0.6000\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8880 - accuracy: 0.6833 - val_loss: 0.8971 - val_accuracy: 0.6000\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8855 - accuracy: 0.6833 - val_loss: 0.8944 - val_accuracy: 0.6000\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8830 - accuracy: 0.6833 - val_loss: 0.8920 - val_accuracy: 0.6000\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8805 - accuracy: 0.6833 - val_loss: 0.8896 - val_accuracy: 0.6000\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8780 - accuracy: 0.6833 - val_loss: 0.8873 - val_accuracy: 0.6000\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8754 - accuracy: 0.6833 - val_loss: 0.8850 - val_accuracy: 0.6000\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8730 - accuracy: 0.6833 - val_loss: 0.8827 - val_accuracy: 0.6000\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8705 - accuracy: 0.6833 - val_loss: 0.8803 - val_accuracy: 0.6000\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8679 - accuracy: 0.6833 - val_loss: 0.8779 - val_accuracy: 0.6000\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8655 - accuracy: 0.6833 - val_loss: 0.8756 - val_accuracy: 0.6000\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8630 - accuracy: 0.6833 - val_loss: 0.8731 - val_accuracy: 0.6000\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8607 - accuracy: 0.6833 - val_loss: 0.8708 - val_accuracy: 0.6000\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8581 - accuracy: 0.6833 - val_loss: 0.8686 - val_accuracy: 0.6000\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8557 - accuracy: 0.6833 - val_loss: 0.8662 - val_accuracy: 0.6000\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8532 - accuracy: 0.6833 - val_loss: 0.8638 - val_accuracy: 0.6000\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8508 - accuracy: 0.6833 - val_loss: 0.8615 - val_accuracy: 0.6000\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8483 - accuracy: 0.6833 - val_loss: 0.8592 - val_accuracy: 0.6000\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8459 - accuracy: 0.6833 - val_loss: 0.8568 - val_accuracy: 0.6000\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8435 - accuracy: 0.6833 - val_loss: 0.8546 - val_accuracy: 0.6000\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8412 - accuracy: 0.6833 - val_loss: 0.8522 - val_accuracy: 0.6000\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8387 - accuracy: 0.6833 - val_loss: 0.8499 - val_accuracy: 0.6000\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8363 - accuracy: 0.6833 - val_loss: 0.8476 - val_accuracy: 0.6000\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8340 - accuracy: 0.6917 - val_loss: 0.8455 - val_accuracy: 0.6000\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8316 - accuracy: 0.6917 - val_loss: 0.8432 - val_accuracy: 0.6000\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8293 - accuracy: 0.6917 - val_loss: 0.8409 - val_accuracy: 0.6000\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8269 - accuracy: 0.6917 - val_loss: 0.8386 - val_accuracy: 0.6000\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8246 - accuracy: 0.6917 - val_loss: 0.8364 - val_accuracy: 0.6000\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8223 - accuracy: 0.6917 - val_loss: 0.8341 - val_accuracy: 0.6000\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8200 - accuracy: 0.6917 - val_loss: 0.8319 - val_accuracy: 0.6000\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8177 - accuracy: 0.6917 - val_loss: 0.8298 - val_accuracy: 0.6000\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8154 - accuracy: 0.6917 - val_loss: 0.8276 - val_accuracy: 0.6000\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8131 - accuracy: 0.6917 - val_loss: 0.8255 - val_accuracy: 0.6000\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8109 - accuracy: 0.6917 - val_loss: 0.8234 - val_accuracy: 0.6000\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8086 - accuracy: 0.6917 - val_loss: 0.8213 - val_accuracy: 0.6000\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8064 - accuracy: 0.6917 - val_loss: 0.8191 - val_accuracy: 0.6000\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8042 - accuracy: 0.6917 - val_loss: 0.8170 - val_accuracy: 0.6000\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8020 - accuracy: 0.6917 - val_loss: 0.8151 - val_accuracy: 0.6000\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7998 - accuracy: 0.6917 - val_loss: 0.8131 - val_accuracy: 0.6000\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7976 - accuracy: 0.6917 - val_loss: 0.8111 - val_accuracy: 0.6000\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7954 - accuracy: 0.6917 - val_loss: 0.8090 - val_accuracy: 0.6000\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7932 - accuracy: 0.7000 - val_loss: 0.8071 - val_accuracy: 0.6000\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7910 - accuracy: 0.7000 - val_loss: 0.8051 - val_accuracy: 0.6000\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7888 - accuracy: 0.7000 - val_loss: 0.8030 - val_accuracy: 0.6000\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7868 - accuracy: 0.7000 - val_loss: 0.8008 - val_accuracy: 0.6000\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7844 - accuracy: 0.7000 - val_loss: 0.7988 - val_accuracy: 0.6000\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7824 - accuracy: 0.7000 - val_loss: 0.7967 - val_accuracy: 0.6000\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7801 - accuracy: 0.7000 - val_loss: 0.7946 - val_accuracy: 0.6000\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7779 - accuracy: 0.7000 - val_loss: 0.7924 - val_accuracy: 0.6000\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7758 - accuracy: 0.7000 - val_loss: 0.7901 - val_accuracy: 0.6000\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7733 - accuracy: 0.7083 - val_loss: 0.7871 - val_accuracy: 0.6000\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7704 - accuracy: 0.7083 - val_loss: 0.7838 - val_accuracy: 0.5667\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7675 - accuracy: 0.7250 - val_loss: 0.7807 - val_accuracy: 0.6000\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7644 - accuracy: 0.7417 - val_loss: 0.7774 - val_accuracy: 0.7000\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7605 - accuracy: 0.7750 - val_loss: 0.7733 - val_accuracy: 0.7667\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7571 - accuracy: 0.7583 - val_loss: 0.7690 - val_accuracy: 0.7667\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7540 - accuracy: 0.8000 - val_loss: 0.7656 - val_accuracy: 0.7333\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7507 - accuracy: 0.8333 - val_loss: 0.7625 - val_accuracy: 0.7333\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7475 - accuracy: 0.8333 - val_loss: 0.7596 - val_accuracy: 0.7667\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7445 - accuracy: 0.8250 - val_loss: 0.7568 - val_accuracy: 0.8000\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7416 - accuracy: 0.8333 - val_loss: 0.7539 - val_accuracy: 0.8000\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7387 - accuracy: 0.8333 - val_loss: 0.7509 - val_accuracy: 0.8333\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7359 - accuracy: 0.8333 - val_loss: 0.7479 - val_accuracy: 0.7667\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7329 - accuracy: 0.8417 - val_loss: 0.7452 - val_accuracy: 0.8333\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7300 - accuracy: 0.8417 - val_loss: 0.7423 - val_accuracy: 0.7667\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7271 - accuracy: 0.8500 - val_loss: 0.7395 - val_accuracy: 0.7667\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7243 - accuracy: 0.8500 - val_loss: 0.7368 - val_accuracy: 0.7667\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7216 - accuracy: 0.8500 - val_loss: 0.7340 - val_accuracy: 0.8000\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7187 - accuracy: 0.8500 - val_loss: 0.7314 - val_accuracy: 0.8333\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7159 - accuracy: 0.8500 - val_loss: 0.7287 - val_accuracy: 0.8333\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7131 - accuracy: 0.8583 - val_loss: 0.7261 - val_accuracy: 0.8667\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7103 - accuracy: 0.8583 - val_loss: 0.7234 - val_accuracy: 0.8667\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7076 - accuracy: 0.8667 - val_loss: 0.7209 - val_accuracy: 0.9000\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7049 - accuracy: 0.8667 - val_loss: 0.7183 - val_accuracy: 0.9000\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7022 - accuracy: 0.8667 - val_loss: 0.7157 - val_accuracy: 0.8667\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6995 - accuracy: 0.8667 - val_loss: 0.7132 - val_accuracy: 0.9000\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6969 - accuracy: 0.8667 - val_loss: 0.7107 - val_accuracy: 0.9000\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.8833 - val_loss: 0.7081 - val_accuracy: 0.9000\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6915 - accuracy: 0.8833 - val_loss: 0.7056 - val_accuracy: 0.9000\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6889 - accuracy: 0.8833 - val_loss: 0.7031 - val_accuracy: 0.8667\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6863 - accuracy: 0.8917 - val_loss: 0.7007 - val_accuracy: 0.9000\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6838 - accuracy: 0.9000 - val_loss: 0.6982 - val_accuracy: 0.9000\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6813 - accuracy: 0.9000 - val_loss: 0.6957 - val_accuracy: 0.8667\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6786 - accuracy: 0.9083 - val_loss: 0.6933 - val_accuracy: 0.8667\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6762 - accuracy: 0.9083 - val_loss: 0.6909 - val_accuracy: 0.9000\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6735 - accuracy: 0.9083 - val_loss: 0.6886 - val_accuracy: 0.9000\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6710 - accuracy: 0.9167 - val_loss: 0.6862 - val_accuracy: 0.9000\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6686 - accuracy: 0.9167 - val_loss: 0.6838 - val_accuracy: 0.9000\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6662 - accuracy: 0.9167 - val_loss: 0.6815 - val_accuracy: 0.9000\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6637 - accuracy: 0.9167 - val_loss: 0.6792 - val_accuracy: 0.9000\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6613 - accuracy: 0.9167 - val_loss: 0.6769 - val_accuracy: 0.9000\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6590 - accuracy: 0.9167 - val_loss: 0.6745 - val_accuracy: 0.9000\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6566 - accuracy: 0.9167 - val_loss: 0.6723 - val_accuracy: 0.9000\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6542 - accuracy: 0.9167 - val_loss: 0.6700 - val_accuracy: 0.9000\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6519 - accuracy: 0.9167 - val_loss: 0.6678 - val_accuracy: 0.9333\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6496 - accuracy: 0.9167 - val_loss: 0.6655 - val_accuracy: 0.9333\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6473 - accuracy: 0.9250 - val_loss: 0.6634 - val_accuracy: 0.9333\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6450 - accuracy: 0.9250 - val_loss: 0.6611 - val_accuracy: 0.9333\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6428 - accuracy: 0.9250 - val_loss: 0.6589 - val_accuracy: 0.9333\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6405 - accuracy: 0.9333 - val_loss: 0.6567 - val_accuracy: 0.9333\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6382 - accuracy: 0.9250 - val_loss: 0.6545 - val_accuracy: 0.9333\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6361 - accuracy: 0.9333 - val_loss: 0.6524 - val_accuracy: 0.9333\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6340 - accuracy: 0.9417 - val_loss: 0.6503 - val_accuracy: 0.9333\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6318 - accuracy: 0.9417 - val_loss: 0.6482 - val_accuracy: 0.9333\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6298 - accuracy: 0.9500 - val_loss: 0.6462 - val_accuracy: 0.9333\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6275 - accuracy: 0.9500 - val_loss: 0.6441 - val_accuracy: 0.9333\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6254 - accuracy: 0.9500 - val_loss: 0.6421 - val_accuracy: 0.9333\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6235 - accuracy: 0.9500 - val_loss: 0.6400 - val_accuracy: 0.9333\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6214 - accuracy: 0.9583 - val_loss: 0.6380 - val_accuracy: 0.9333\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6194 - accuracy: 0.9583 - val_loss: 0.6361 - val_accuracy: 0.9333\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6173 - accuracy: 0.9583 - val_loss: 0.6342 - val_accuracy: 0.9333\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6153 - accuracy: 0.9667 - val_loss: 0.6322 - val_accuracy: 0.9333\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6135 - accuracy: 0.9667 - val_loss: 0.6304 - val_accuracy: 0.9333\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6115 - accuracy: 0.9667 - val_loss: 0.6285 - val_accuracy: 0.9333\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6095 - accuracy: 0.9750 - val_loss: 0.6266 - val_accuracy: 0.9333\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6076 - accuracy: 0.9750 - val_loss: 0.6247 - val_accuracy: 0.9333\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6057 - accuracy: 0.9750 - val_loss: 0.6229 - val_accuracy: 0.9333\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6038 - accuracy: 0.9750 - val_loss: 0.6210 - val_accuracy: 0.9333\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6019 - accuracy: 0.9750 - val_loss: 0.6192 - val_accuracy: 0.9333\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6000 - accuracy: 0.9750 - val_loss: 0.6173 - val_accuracy: 0.9333\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5982 - accuracy: 0.9750 - val_loss: 0.6155 - val_accuracy: 0.9333\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5964 - accuracy: 0.9750 - val_loss: 0.6137 - val_accuracy: 0.9333\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5945 - accuracy: 0.9750 - val_loss: 0.6119 - val_accuracy: 0.9333\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5926 - accuracy: 0.9750 - val_loss: 0.6101 - val_accuracy: 0.9333\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5908 - accuracy: 0.9750 - val_loss: 0.6084 - val_accuracy: 0.9333\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5891 - accuracy: 0.9750 - val_loss: 0.6066 - val_accuracy: 0.9333\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5873 - accuracy: 0.9750 - val_loss: 0.6048 - val_accuracy: 0.9333\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5856 - accuracy: 0.9750 - val_loss: 0.6031 - val_accuracy: 0.9333\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5838 - accuracy: 0.9750 - val_loss: 0.6014 - val_accuracy: 0.9333\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5822 - accuracy: 0.9750 - val_loss: 0.5996 - val_accuracy: 0.9333\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5803 - accuracy: 0.9750 - val_loss: 0.5980 - val_accuracy: 0.9333\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5786 - accuracy: 0.9750 - val_loss: 0.5963 - val_accuracy: 0.9333\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5770 - accuracy: 0.9750 - val_loss: 0.5947 - val_accuracy: 0.9333\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5752 - accuracy: 0.9750 - val_loss: 0.5931 - val_accuracy: 0.9333\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5735 - accuracy: 0.9750 - val_loss: 0.5914 - val_accuracy: 0.9333\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5719 - accuracy: 0.9750 - val_loss: 0.5897 - val_accuracy: 0.9333\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5703 - accuracy: 0.9750 - val_loss: 0.5881 - val_accuracy: 0.9333\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5686 - accuracy: 0.9750 - val_loss: 0.5865 - val_accuracy: 0.9333\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5669 - accuracy: 0.9750 - val_loss: 0.5849 - val_accuracy: 0.9333\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5654 - accuracy: 0.9750 - val_loss: 0.5833 - val_accuracy: 0.9333\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5639 - accuracy: 0.9750 - val_loss: 0.5817 - val_accuracy: 0.9333\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5621 - accuracy: 0.9750 - val_loss: 0.5801 - val_accuracy: 0.9333\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5606 - accuracy: 0.9750 - val_loss: 0.5785 - val_accuracy: 0.9333\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5590 - accuracy: 0.9750 - val_loss: 0.5769 - val_accuracy: 0.9333\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5574 - accuracy: 0.9750 - val_loss: 0.5753 - val_accuracy: 0.9333\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5558 - accuracy: 0.9750 - val_loss: 0.5737 - val_accuracy: 0.9333\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5543 - accuracy: 0.9750 - val_loss: 0.5721 - val_accuracy: 0.9333\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5527 - accuracy: 0.9750 - val_loss: 0.5706 - val_accuracy: 0.9333\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5512 - accuracy: 0.9750 - val_loss: 0.5691 - val_accuracy: 0.9333\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5497 - accuracy: 0.9750 - val_loss: 0.5676 - val_accuracy: 0.9333\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5480 - accuracy: 0.9750 - val_loss: 0.5660 - val_accuracy: 0.9333\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5466 - accuracy: 0.9750 - val_loss: 0.5645 - val_accuracy: 0.9333\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5452 - accuracy: 0.9750 - val_loss: 0.5631 - val_accuracy: 0.9333\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5436 - accuracy: 0.9750 - val_loss: 0.5615 - val_accuracy: 0.9333\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.9750 - val_loss: 0.5600 - val_accuracy: 0.9333\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5407 - accuracy: 0.9750 - val_loss: 0.5585 - val_accuracy: 0.9333\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5392 - accuracy: 0.9750 - val_loss: 0.5571 - val_accuracy: 0.9333\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5377 - accuracy: 0.9750 - val_loss: 0.5556 - val_accuracy: 0.9333\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5362 - accuracy: 0.9750 - val_loss: 0.5542 - val_accuracy: 0.9333\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5348 - accuracy: 0.9750 - val_loss: 0.5529 - val_accuracy: 0.9333\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5334 - accuracy: 0.9750 - val_loss: 0.5515 - val_accuracy: 0.9333\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5321 - accuracy: 0.9750 - val_loss: 0.5500 - val_accuracy: 0.9333\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5306 - accuracy: 0.9750 - val_loss: 0.5486 - val_accuracy: 0.9333\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.9750 - val_loss: 0.5472 - val_accuracy: 0.9333\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5279 - accuracy: 0.9750 - val_loss: 0.5457 - val_accuracy: 0.9333\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5264 - accuracy: 0.9750 - val_loss: 0.5442 - val_accuracy: 0.9333\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5251 - accuracy: 0.9750 - val_loss: 0.5428 - val_accuracy: 0.9333\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5238 - accuracy: 0.9750 - val_loss: 0.5414 - val_accuracy: 0.9333\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5225 - accuracy: 0.9750 - val_loss: 0.5400 - val_accuracy: 0.9333\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5210 - accuracy: 0.9750 - val_loss: 0.5388 - val_accuracy: 0.9333\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5195 - accuracy: 0.9750 - val_loss: 0.5374 - val_accuracy: 0.9333\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.9750 - val_loss: 0.5361 - val_accuracy: 0.9333\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5170 - accuracy: 0.9750 - val_loss: 0.5348 - val_accuracy: 0.9333\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.9750 - val_loss: 0.5335 - val_accuracy: 0.9333\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5142 - accuracy: 0.9750 - val_loss: 0.5321 - val_accuracy: 0.9333\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5130 - accuracy: 0.9750 - val_loss: 0.5307 - val_accuracy: 0.9333\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5117 - accuracy: 0.9750 - val_loss: 0.5294 - val_accuracy: 0.9333\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5104 - accuracy: 0.9750 - val_loss: 0.5282 - val_accuracy: 0.9333\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5091 - accuracy: 0.9750 - val_loss: 0.5270 - val_accuracy: 0.9333\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5078 - accuracy: 0.9750 - val_loss: 0.5257 - val_accuracy: 0.9333\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5065 - accuracy: 0.9750 - val_loss: 0.5245 - val_accuracy: 0.9333\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5052 - accuracy: 0.9750 - val_loss: 0.5233 - val_accuracy: 0.9333\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5040 - accuracy: 0.9750 - val_loss: 0.5221 - val_accuracy: 0.9333\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.9750 - val_loss: 0.5209 - val_accuracy: 0.9333\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5016 - accuracy: 0.9750 - val_loss: 0.5195 - val_accuracy: 0.9333\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.9750 - val_loss: 0.5182 - val_accuracy: 0.9333\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.9750 - val_loss: 0.5170 - val_accuracy: 0.9333\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4977 - accuracy: 0.9750 - val_loss: 0.5158 - val_accuracy: 0.9333\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4966 - accuracy: 0.9750 - val_loss: 0.5145 - val_accuracy: 0.9333\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.9750 - val_loss: 0.5133 - val_accuracy: 0.9333\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.9750 - val_loss: 0.5121 - val_accuracy: 0.9333\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4929 - accuracy: 0.9750 - val_loss: 0.5108 - val_accuracy: 0.9333\n",
      "Epoch 291/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4916 - accuracy: 0.9750 - val_loss: 0.5096 - val_accuracy: 0.9333\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4905 - accuracy: 0.9750 - val_loss: 0.5083 - val_accuracy: 0.9333\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4893 - accuracy: 0.9750 - val_loss: 0.5071 - val_accuracy: 0.9333\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4882 - accuracy: 0.9750 - val_loss: 0.5059 - val_accuracy: 0.9333\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.9750 - val_loss: 0.5047 - val_accuracy: 0.9333\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.9750 - val_loss: 0.5035 - val_accuracy: 0.9333\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4845 - accuracy: 0.9750 - val_loss: 0.5023 - val_accuracy: 0.9333\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4834 - accuracy: 0.9750 - val_loss: 0.5011 - val_accuracy: 0.9333\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.9750 - val_loss: 0.5000 - val_accuracy: 0.9333\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.9750 - val_loss: 0.4988 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x149c84390>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train, y=y_train, epochs=300,\n",
    "         validation_data=(scaled_X_test, y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.206895</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>1.201239</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.201425</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>1.196088</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.196538</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>1.190775</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.191278</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.185684</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.186343</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.180701</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.485713</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.503514</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.484531</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.502282</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.483386</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.501117</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.482305</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.499989</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.481052</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.498798</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    1.206895  0.158333  1.201239      0.100000\n",
       "1    1.201425  0.158333  1.196088      0.100000\n",
       "2    1.196538  0.141667  1.190775      0.100000\n",
       "3    1.191278  0.125000  1.185684      0.133333\n",
       "4    1.186343  0.100000  1.180701      0.133333\n",
       "..        ...       ...       ...           ...\n",
       "295  0.485713  0.975000  0.503514      0.933333\n",
       "296  0.484531  0.975000  0.502282      0.933333\n",
       "297  0.483386  0.975000  0.501117      0.933333\n",
       "298  0.482305  0.975000  0.499989      0.933333\n",
       "299  0.481052  0.975000  0.498798      0.933333\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14af75d30>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14a944e10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4987982511520386, 0.9333333373069763]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make best model possible with all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = len(metrics)\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units = 4, activation='relu', input_shape=[4,]))\n",
    "model.add(Dense(units = 3, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0960 - accuracy: 0.3933\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0939 - accuracy: 0.4000\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0920 - accuracy: 0.4000\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0903 - accuracy: 0.4133\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0884 - accuracy: 0.4600\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0862 - accuracy: 0.5133\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0843 - accuracy: 0.5533\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0822 - accuracy: 0.5867\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0801 - accuracy: 0.6133\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0778 - accuracy: 0.6333\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0756 - accuracy: 0.6533\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0729 - accuracy: 0.6533\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0697 - accuracy: 0.6667\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0664 - accuracy: 0.6667\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0624 - accuracy: 0.6667\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0582 - accuracy: 0.6667\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0535 - accuracy: 0.6667\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0489 - accuracy: 0.6600\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0441 - accuracy: 0.6600\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0391 - accuracy: 0.6600\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0340 - accuracy: 0.6600\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0287 - accuracy: 0.6600\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0233 - accuracy: 0.6600\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0179 - accuracy: 0.6600\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0122 - accuracy: 0.6600\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0065 - accuracy: 0.6600\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0007 - accuracy: 0.6600\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9951 - accuracy: 0.6600\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9894 - accuracy: 0.6600\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9839 - accuracy: 0.6600\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9782 - accuracy: 0.6600\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9726 - accuracy: 0.6600\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9670 - accuracy: 0.6600\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 971us/step - loss: 0.9615 - accuracy: 0.6600\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9559 - accuracy: 0.6600\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9504 - accuracy: 0.6600\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9448 - accuracy: 0.6600\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9393 - accuracy: 0.6600\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9337 - accuracy: 0.6600\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9283 - accuracy: 0.6600\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9226 - accuracy: 0.6667\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9170 - accuracy: 0.6667\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9115 - accuracy: 0.6667\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9058 - accuracy: 0.6667\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9001 - accuracy: 0.6667\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8946 - accuracy: 0.6667\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8890 - accuracy: 0.6667\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8831 - accuracy: 0.6667\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8775 - accuracy: 0.6600\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8719 - accuracy: 0.6667\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8661 - accuracy: 0.6667\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8604 - accuracy: 0.6667\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8547 - accuracy: 0.6667\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8489 - accuracy: 0.6667\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8433 - accuracy: 0.6667\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8376 - accuracy: 0.6667\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8319 - accuracy: 0.6667\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8261 - accuracy: 0.6667\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8205 - accuracy: 0.6733\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8149 - accuracy: 0.6733\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8093 - accuracy: 0.6733\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8037 - accuracy: 0.6733\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7982 - accuracy: 0.6733\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7927 - accuracy: 0.6733\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7873 - accuracy: 0.6733\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7818 - accuracy: 0.6733\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7764 - accuracy: 0.6733\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7710 - accuracy: 0.6733\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7659 - accuracy: 0.6733\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7605 - accuracy: 0.6800\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7553 - accuracy: 0.6867\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7501 - accuracy: 0.6933\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7450 - accuracy: 0.6933\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7397 - accuracy: 0.6933\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.7347 - accuracy: 0.6933\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7299 - accuracy: 0.6933\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6933\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.6933\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.7000\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.7000\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7057 - accuracy: 0.7000\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7011 - accuracy: 0.7000\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.7000\n",
      "Epoch 84/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.7000\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.7000\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.7000\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6791 - accuracy: 0.7000\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6747 - accuracy: 0.7000\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6705 - accuracy: 0.7000\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6666 - accuracy: 0.7000\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6623 - accuracy: 0.7000\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6583 - accuracy: 0.7000\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.7000\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.7000\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6467 - accuracy: 0.7000\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.7000\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6391 - accuracy: 0.7000\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6355 - accuracy: 0.7000\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6320 - accuracy: 0.7000\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.7000\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.7000\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6214 - accuracy: 0.7000\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6180 - accuracy: 0.7000\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6147 - accuracy: 0.7000\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6114 - accuracy: 0.7000\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6081 - accuracy: 0.7000\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6049 - accuracy: 0.7000\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6017 - accuracy: 0.7000\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 991us/step - loss: 0.5986 - accuracy: 0.7000\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5956 - accuracy: 0.7000\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5925 - accuracy: 0.7000\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5896 - accuracy: 0.7000\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5867 - accuracy: 0.7067\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.7067\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5810 - accuracy: 0.7067\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5783 - accuracy: 0.7067\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5756 - accuracy: 0.7067\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.7067\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5701 - accuracy: 0.7067\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.7067\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5648 - accuracy: 0.7067\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7067\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5597 - accuracy: 0.7067\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7067\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7067\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5526 - accuracy: 0.7067\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5501 - accuracy: 0.7067\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7067\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7067\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7067\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5412 - accuracy: 0.7067\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5391 - accuracy: 0.7067\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5370 - accuracy: 0.7067\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5349 - accuracy: 0.7067\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7067\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7067\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.7067\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5270 - accuracy: 0.7067\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7067\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.7133\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7133\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.7133\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7133\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7133\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5143 - accuracy: 0.7200\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.7333\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.7400\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.7333\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7333\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.7400\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7400\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.7400\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7400\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.7400\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.7400\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7400\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7400\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7400\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.7400\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.7400\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.7400\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7400\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.7467\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.7533\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.7600\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.7600\n",
      "Epoch 167/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7733\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7733\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7733\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.7800\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.7867\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7867\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7867\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.7867\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7867\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7867\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7867\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7867\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7867\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7933\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7933\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.8000\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.8067\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.8067\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.8133\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.8133\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.8200\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.8267\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.8267\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.8400\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.8400\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.8467\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.8467\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.8467\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.8467\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.8467\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.8533\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.8600\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.8600\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.8733\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.8733\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.8867\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.8933\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4332 - accuracy: 0.8933\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4321 - accuracy: 0.8933\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.9000\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.8933\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.9000\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.9000\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4259 - accuracy: 0.9067\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.9067\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.9067\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.9067\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.9067\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4198 - accuracy: 0.9067\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.9067\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4173 - accuracy: 0.9200\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4160 - accuracy: 0.9333\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.9333\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.9333\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4123 - accuracy: 0.9400\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.9400\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4099 - accuracy: 0.9400\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4087 - accuracy: 0.9400\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4074 - accuracy: 0.9400\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4062 - accuracy: 0.9400\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4051 - accuracy: 0.9400\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.9400\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4027 - accuracy: 0.9400\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4014 - accuracy: 0.9400\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4002 - accuracy: 0.9400\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3990 - accuracy: 0.9400\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3979 - accuracy: 0.9400\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3967 - accuracy: 0.9400\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.9400\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3942 - accuracy: 0.9400\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3930 - accuracy: 0.9400\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.9400\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3907 - accuracy: 0.9400\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3895 - accuracy: 0.9400\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3883 - accuracy: 0.9400\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3871 - accuracy: 0.9400\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3858 - accuracy: 0.9400\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3846 - accuracy: 0.9400\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3834 - accuracy: 0.9400\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.9400\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3810 - accuracy: 0.9467\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3798 - accuracy: 0.9467\n",
      "Epoch 249/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.9467\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.9467\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3763 - accuracy: 0.9467\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.9467\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3739 - accuracy: 0.9467\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3727 - accuracy: 0.9467\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.9467\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.9467\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3693 - accuracy: 0.9467\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.9467\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3669 - accuracy: 0.9467\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.9467\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3646 - accuracy: 0.9533\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.9533\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3622 - accuracy: 0.9533\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.9533\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3600 - accuracy: 0.9533\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.9533\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3577 - accuracy: 0.9533\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3565 - accuracy: 0.9533\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.9533\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3542 - accuracy: 0.9533\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3532 - accuracy: 0.9533\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.9533\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3509 - accuracy: 0.9533\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3497 - accuracy: 0.9600\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3486 - accuracy: 0.9600\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.9600\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.9600\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3452 - accuracy: 0.9667\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3440 - accuracy: 0.9667\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.9667\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.9667\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3407 - accuracy: 0.9667\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3397 - accuracy: 0.9667\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.9667\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.9667\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3363 - accuracy: 0.9667\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.9667\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.9667\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.9667\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.9667\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.9667\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.9667\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.9667\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.9667\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3265 - accuracy: 0.9667\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3256 - accuracy: 0.9667\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.9667\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3234 - accuracy: 0.9667\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3224 - accuracy: 0.9667\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14a68a780>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X, y, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Bryan/Documents/Programming/Python_Courses/Tensorflow2'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_iris_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model('final_iris_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_scaler = joblib.load('iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Single Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {'sepal_length':5.1,\n",
    "                 'sepal_width':3.5,\n",
    "                 'petal_length':1.4,\n",
    "                 'petal_width':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the classes from the encoder\n",
    "# index locations 0, 1, 2\n",
    "\n",
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model, scaler, sample_json):\n",
    "    \n",
    "    s_len = sample_json[\"sepal_length\"]\n",
    "    s_wid = sample_json[\"sepal_width\"]\n",
    "    p_len = sample_json[\"petal_length\"]\n",
    "    p_wid = sample_json[\"petal_width\"]\n",
    "    \n",
    "    flower = [[s_len, s_wid, p_len, p_wid]]\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    # get the returned index\n",
    "    class_index = model.predict_classes(flower)[0]\n",
    "    \n",
    "    # return the class\n",
    "    return classes[class_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(flower_model, flower_scaler, flower_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up code for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "flower_model = load_model('final_iris_model.h5')\n",
    "flower_scaler = joblib.load('iris_scaler.pkl')\n",
    "\n",
    "\n",
    "def return_prediction(model, scaler, sample_json):\n",
    "    \n",
    "    s_len = sample_json[\"sepal_length\"]\n",
    "    s_wid = sample_json[\"sepal_width\"]\n",
    "    p_len = sample_json[\"petal_length\"]\n",
    "    p_wid = sample_json[\"petal_width\"]\n",
    "    \n",
    "    flower = [[s_len, s_wid, p_len, p_wid]]\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    # get the returned index\n",
    "    class_index = model.predict_classes(flower)[0]\n",
    "    \n",
    "    # return the class\n",
    "    return classes[class_index]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
